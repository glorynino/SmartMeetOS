# agents/actions.py
"""
SystÃ¨me COMPLET utilisant 100% des capacitÃ©s LangChain :
- Agents autonomes avec tool calling
- Memory (historique des transcriptions)
- Chains complexes
- Orchestration automatique
- Callbacks pour observabilitÃ©
"""

import os
import sys
from pathlib import Path
import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime
from dotenv import load_dotenv

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from services.discord_client import DiscordClient
from typing import cast

# LangChain COMPLET - Imports pour version 1.2.x
from langchain_mistralai import ChatMistralAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.runnables import RunnablePassthrough, RunnableSequence

# Pour LangChain 1.2.x, on utilise LangGraph
try:
    from langgraph.prebuilt import create_react_agent
    USING_LANGGRAPH = True
    print("âœ… Utilisation de LangGraph (version 1.2.x)")
except ImportError:
    USING_LANGGRAPH = False
    print("âš ï¸ LangGraph non disponible")

# Memory locale (plus fiable)
class ConversationBufferMemory:
    def __init__(self, memory_key="chat_history", return_messages=False):
        self.memory_key = memory_key
        self.return_messages = return_messages
        self.buffer = []

    def add_message(self, message):
        self.buffer.append(message)

    def save_context(self, inputs, outputs):
        self.buffer.append({"input": inputs, "output": outputs})

    def load_memory_variables(self, inputs):
        if self.return_messages:
            return {self.memory_key: self.buffer.copy()}
        else:
            return {self.memory_key: "\n".join(str(m) for m in self.buffer)}

from pydantic import BaseModel, Field

load_dotenv()

# STUDENT_ID = tu m'es L'id de la personne que tu veux notifier

# Ã‰tat global Discord (typÃ© correctement)
discord_client_instance: Optional[DiscordClient] = None

# ============================================
# CALLBACK HANDLER (ObservabilitÃ©)
# ============================================

class SmartMeetOSCallbackHandler(BaseCallbackHandler):
    """
    Callback pour observer TOUT ce que fait l'agent en temps rÃ©el.
    C'est une feature clÃ© de LangChain pour le debugging et monitoring.
    """
    
    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs) -> None:
        """AppelÃ© quand le LLM commence Ã  rÃ©flÃ©chir"""
        print("\nðŸ§  LLM Start : L'agent rÃ©flÃ©chit...")
    
    def on_llm_end(self, response, **kwargs) -> None:
        """AppelÃ© quand le LLM a fini de rÃ©flÃ©chir"""
        print("âœ… LLM End : RÃ©flexion terminÃ©e")
    
    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs) -> None:
        """AppelÃ© quand un tool est appelÃ©"""
        tool_name = serialized.get("name", "unknown")
        print(f"\nðŸ”§ Tool Start : {tool_name}")
        print(f"   Input : {input_str[:100]}...")
    
    def on_tool_end(self, output: str, **kwargs) -> None:
        """AppelÃ© quand un tool a terminÃ©"""
        print(f"âœ… Tool End : {output[:100]}...")
    
    def on_agent_action(self, action, **kwargs) -> None:
        """AppelÃ© quand l'agent dÃ©cide d'une action"""
        print(f"\nðŸŽ¯ Agent Action : {action.tool}")
        print(f"   Reasoning : {str(action.log)[:200]}...")
    
    def on_agent_finish(self, finish, **kwargs) -> None:
        """AppelÃ© quand l'agent termine"""
        print(f"\nðŸ Agent Finish : {str(finish.return_values.get('output', ''))[:200]}...")

# ============================================
# MODÃˆLES PYDANTIC POUR STRUCTURED OUTPUT
# ============================================

class TranscriptAnalysisResult(BaseModel):
    """RÃ©sultat structurÃ© de l'analyse"""
    has_important_info: bool = Field(description="Y a-t-il des infos importantes ?")
    event_type: str = Field(
        description="Type principal d'Ã©vÃ©nement",
        pattern="^(meeting|exam|test|deadline|homework|announcement|other|none)$"
    )
    urgency: str = Field(
        description="Niveau d'urgence global",
        pattern="^(high|medium|low|none)$"
    )
    key_points: List[str] = Field(description="Points clÃ©s Ã  retenir")
    summary: str = Field(description="RÃ©sumÃ© en une phrase")
    confidence: float = Field(ge=0.0, le=1.0, description="Confiance de l'analyse")
    date_mentioned: Optional[str] = Field(default=None, description="Date mentionnÃ©e si prÃ©sente")
    time_mentioned: Optional[str] = Field(default=None, description="Heure mentionnÃ©e si prÃ©sente")

# ============================================
# TOOLS LANGCHAIN
# ============================================

@tool
def analyze_transcript_deep(transcript: str) -> dict:
    """
    Analyse en profondeur une transcription avec un LLM dÃ©diÃ©.
    Ce tool utilise LUI-MÃŠME un LLM pour l'analyse (multi-agent pattern).
    
    Args:
        transcript: La transcription Ã  analyser
        
    Returns:
        Analyse structurÃ©e avec Ã©vÃ©nements dÃ©tectÃ©s
    """
    print(f"ðŸ” Tool: Analyse profonde de {len(transcript)} caractÃ¨res...")
    
    # Ce tool utilise son PROPRE LLM (pattern multi-agent)
    analyzer_llm = ChatMistralAI(
        model_name="mistral-large-latest",  # model_name au lieu de model
        api_key=os.getenv("MISTRAL_API_KEY"),
        temperature=0.1
    )
    
    # Chain spÃ©cialisÃ©e pour l'analyse
    analyzer_prompt = ChatPromptTemplate.from_messages([
        ("system", """Tu es un expert en analyse de transcriptions Ã©ducatives.

Analyse cette transcription et identifie :
- Type d'Ã©vÃ©nement (meeting, exam, test, deadline, etc.)
- Niveau d'urgence (high, medium, low)
- Points clÃ©s importants
- Dates et heures mentionnÃ©es

Important : meetings, examens, deadlines = high priority
Bavardage, discussions informelles = low priority ou none

Retourne un JSON structurÃ©."""),
        ("human", "{transcript}")
    ])
    
    chain = analyzer_prompt | analyzer_llm
    result = chain.invoke({"transcript": transcript})
    
    # Parse la rÃ©ponse
    import json
    try:
        # Tente de parser le JSON
        content = result.content if isinstance(result.content, str) else str(result.content)
        
        # Nettoie les backticks markdown si prÃ©sents
        if "```json" in content:
            parts = content.split("```json")
            if len(parts) > 1:
                content = parts[1].split("```")[0]
        elif "```" in content:
            parts = content.split("```")
            if len(parts) > 1:
                content = parts[1].split("```")[0]
        
        analysis = json.loads(content.strip())
        
        # Valide la structure
        if not all(k in analysis for k in ["has_important_info", "event_type", "urgency", "summary"]):
            raise ValueError("Structure JSON incomplÃ¨te")
        
        return analysis
    
    except Exception as e:
        print(f"âš ï¸  Erreur parsing, analyse par dÃ©faut : {e}")
        # Fallback : analyse simple par mots-clÃ©s
        keywords_high = ["meeting", "rÃ©union", "exam", "interro", "urgent", "deadline"]
        keywords_med = ["homework", "devoir", "projet", "rendu"]
        
        has_important = any(k in transcript.lower() for k in keywords_high + keywords_med)
        
        if any(k in transcript.lower() for k in keywords_high):
            urgency = "high"
            event_type = "meeting" if "meeting" in transcript.lower() else "exam"
        elif any(k in transcript.lower() for k in keywords_med):
            urgency = "medium"
            event_type = "homework"
        else:
            urgency = "none"
            event_type = "none"
        
        return {
            "has_important_info": has_important,
            "event_type": event_type,
            "urgency": urgency,
            "key_points": ["Analyse automatique par mots-clÃ©s"],
            "summary": "Analyse rapide de la transcription",
            "confidence": 0.7,
            "date_mentioned": None,
            "time_mentioned": None
        }

@tool
def check_previous_transcripts(query: str) -> str:
    """
    VÃ©rifie les transcriptions prÃ©cÃ©dentes pour contexte.
    Utilise la MEMORY de LangChain.
    
    Args:
        query: Ce qu'on cherche dans l'historique
        
    Returns:
        Contexte des transcriptions prÃ©cÃ©dentes
    """
    print(f"ðŸ“š Tool: Recherche dans l'historique : '{query}'")
    
    # Ici tu pourrais utiliser un vector store (Chroma, Pinecone, etc.)
    # Pour l'instant, simulation simple
    
    return "Aucune transcription similaire rÃ©cente trouvÃ©e."

@tool
async def send_discord_notification(user_id: int, message: str, urgency: str = "medium") -> str:
    """
    Envoie une notification Discord Ã  un Ã©lÃ¨ve.
    
    Args:
        user_id: ID Discord de l'Ã©lÃ¨ve
        message: Message Ã  envoyer
        urgency: Niveau d'urgence (high, medium, low)
        
    Returns:
        Statut de l'envoi
    """
    print(f"ðŸ“¨ Tool: Envoi Discord (urgence: {urgency})")
    
    if not discord_client_instance:
        return "âŒ Discord non initialisÃ©"
    
    # Ajoute un badge d'urgence au message
    if urgency == "high":
        message = f"ðŸš¨ **URGENT** ðŸš¨\n\n{message}"
    elif urgency == "medium":
        message = f"ðŸ“Œ **Important**\n\n{message}"
    
    try:
        success = await discord_client_instance.send_direct_message(user_id, message)
        if success:
            return f"âœ… Notification envoyÃ©e Ã  {user_id}"
        else:
            return f"âŒ Ã‰chec d'envoi Ã  {user_id}"
    except Exception as e:
        return f"âŒ Erreur : {str(e)}"

@tool
def format_for_student(analysis: dict) -> str:
    """
    Formate une analyse en message clair pour un Ã©lÃ¨ve.
    
    Args:
        analysis: RÃ©sultat de l'analyse
        
    Returns:
        Message formatÃ© et clair
    """
    print("âœï¸  Tool: Formatage du message pour l'Ã©lÃ¨ve")
    
    event_icons = {
        "meeting": "ðŸ“…",
        "exam": "ðŸ“",
        "test": "âœï¸",
        "deadline": "â°",
        "homework": "ðŸ“š",
        "announcement": "ðŸ“¢",
        "other": "ðŸ“Œ",
        "none": "ðŸ’¬"
    }
    
    icon = event_icons.get(analysis.get("event_type", "none"), "ðŸ“Œ")
    
    message = f"{icon} **{analysis.get('summary', 'Nouvelle information')}**\n\n"
    
    # Points clÃ©s
    key_points = analysis.get("key_points", [])
    if key_points:
        message += "**Points importants :**\n"
        for point in key_points[:3]:  # Max 3 points
            message += f"â€¢ {point}\n"
        message += "\n"
    
    # Date/Heure si mentionnÃ©
    if analysis.get("date_mentioned"):
        message += f"ðŸ“… Date : {analysis['date_mentioned']}\n"
    if analysis.get("time_mentioned"):
        message += f"â° Heure : {analysis['time_mentioned']}\n"
    
    return message

# ============================================
# AGENT PRINCIPAL (SUPERVISEUR)
# ============================================

class SmartMeetOSAgent:
    """
    Agent superviseur qui orchestre tout le workflow.
    
    Utilise :
    - Tool calling pour dÃ©cisions
    - Memory pour contexte
    - Callbacks pour observabilitÃ©
    - Chains pour sous-tÃ¢ches
    """
    
    def __init__(self, mistral_api_key: str, discord_token: str):
        # LLM principal avec tools
        self.llm = ChatMistralAI(
            model_name="mistral-large-latest",  # model_name au lieu de model
            api_key=mistral_api_key,
            temperature=0.1,
            callbacks=[SmartMeetOSCallbackHandler()]  # ObservabilitÃ©
        )
        
        # Discord
        global discord_client_instance
        discord_client_instance = DiscordClient(token=discord_token)
        
        # Memory (historique des conversations)
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        # Tools disponibles
        self.tools = [
            analyze_transcript_deep,
            check_previous_transcripts,
            format_for_student,
            send_discord_notification
        ]
        
        # CrÃ©e l'agent avec LangGraph (version 1.2.x)
        if USING_LANGGRAPH:
            self.agent = create_react_agent(self.llm, self.tools)
        else:
            raise ImportError("LangGraph requis pour LangChain 1.2.x. Installez: pip install langgraph")
    
    async def process_transcript(self, transcript: str, student_id: int) -> Dict:
        """
        Traite une transcription de maniÃ¨re autonome
        
        Args:
            transcript: La transcription
            student_id: ID Discord de l'Ã©lÃ¨ve
            
        Returns:
            RÃ©sultat complet avec toutes les Ã©tapes
        """
        print("\n" + "="*60)
        print("ðŸ¤– AGENT SUPERVISEUR DÃ‰MARRE")
        print("="*60 + "\n")
        
        try:
            # PrÃ©pare le message systÃ¨me avec instructions
            system_message = f"""Tu es un agent intelligent qui traite des transcriptions pour des Ã©tudiants.

ðŸŽ¯ TA MISSION COMPLÃˆTE :
1. Analyser la transcription avec analyze_transcript_deep
2. VÃ©rifier le contexte avec check_previous_transcripts si nÃ©cessaire
3. DÃ©cider si c'est pertinent pour l'Ã©lÃ¨ve
4. Si OUI :
   a. Formater avec format_for_student
   b. Envoyer avec send_discord_notification
5. Si NON : expliquer pourquoi et s'arrÃªter

ðŸ§  RÃˆGLES DE DÃ‰CISION :
- Urgency "high" â†’ Notifie TOUJOURS
- Urgency "medium" â†’ Notifie si Ã©vÃ©nement proche (< 7 jours)
- Urgency "low" ou "none" â†’ NE notifie PAS
- Bavardage (event_type = "none") â†’ NE notifie JAMAIS

Student ID : {student_id}
Date actuelle : {datetime.now().strftime("%Y-%m-%d")}"""

            user_message = f"""Nouvelle transcription Ã  traiter :

--- TRANSCRIPTION ---
{transcript}
--- FIN TRANSCRIPTION ---

Analyse cette transcription, dÃ©termine si c'est important, et prends les actions appropriÃ©es."""

            # Invoque l'agent avec LangGraph
            messages = [
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ]
            
            result = await self.agent.ainvoke({"messages": messages})
            
            # RÃ©cupÃ¨re la rÃ©ponse finale
            output = ""
            if "messages" in result and isinstance(result["messages"], list):
                for msg in result["messages"]:
                    if hasattr(msg, "content") and isinstance(msg.content, str):
                        output += msg.content + "\n"
            
            # Sauvegarde dans la mÃ©moire
            self.memory.save_context(
                {"input": transcript},
                {"output": output}
            )
            
            print("\n" + "="*60)
            print("âœ… AGENT TERMINÃ‰")
            print("="*60)
            
            return {
                "success": True,
                "output": output,
                "steps": result.get("messages", [])
            }
        
        except Exception as e:
            print(f"\nâŒ Erreur agent : {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}

# ============================================
# FONCTION PRINCIPALE
# ============================================

async def main():
    print("="*60)
    print("ðŸš€ SYSTÃˆME 100% LANGCHAIN")
    print("="*60)
    print("Features:")
    print("  âœ… Agents autonomes avec tool calling")
    print("  âœ… Memory (historique)")
    print("  âœ… Callbacks (observabilitÃ©)")
    print("  âœ… Chains complexes")
    print("  âœ… Multi-agent pattern")
    print("="*60 + "\n")
    
    # Configuration
    mistral_key = os.getenv("MISTRAL_API_KEY")
    discord_token = os.getenv("DISCORD_TOKEN")
    
    if not mistral_key or not discord_token:
        print("âŒ ClÃ©s API manquantes")
        return
    
    print("âœ… Configuration chargÃ©e")
    print(f"ðŸ“¨ Notifications vers : {STUDENT_ID}\n")
    
    # Initialise l'agent superviseur
    print("ðŸ”§ Initialisation de l'agent superviseur...")
    agent = SmartMeetOSAgent(mistral_key, discord_token)
    print("âœ… Agent prÃªt\n")
    
    # ============================================
    # ðŸ”§ TRANSCRIPTIONS DE TEST
    # ============================================
    
    test_transcriptions = [

        {
            "name": "pas important",
            "transcript": """
            On a un meeting super important 
            demain Ã  14h pour le projet final voila , sinon hier je suis sorti avec djad c'etais bien
            """
        }
    ]
    
    # DÃ©marre Discord
    if discord_client_instance is not None:
        @discord_client_instance.client.event
        async def on_ready():
            if discord_client_instance is None:
                return
                
            print(f"ðŸŸ¢ Discord connectÃ© : {discord_client_instance.client.user}\n")
            print("="*60)
            print("ðŸ”„ L'AGENT TRAITE LES TRANSCRIPTIONS")
            print("="*60 + "\n")
            
            for i, test in enumerate(test_transcriptions, 1):
                print(f"\n{'='*60}")
                print(f"ðŸ“„ TEST #{i} : {test['name']}")
                print(f"{'='*60}")
                # strip() appliquÃ© correctement sur une chaÃ®ne
                transcript_text = test['transcript'].strip() if isinstance(test['transcript'], str) else str(test['transcript']).strip()
                print(f"Transcription :\n{transcript_text}\n")
                
                # L'agent dÃ©cide TOUT de maniÃ¨re autonome
                result = await agent.process_transcript(
                    transcript_text,
                    STUDENT_ID
                )
                
                if result["success"]:
                    print(f"\nâœ… Traitement rÃ©ussi")
                    print(f"RÃ©sultat : {result['output']}")
                    print(f"Nombre d'Ã©tapes : {len(result.get('steps', []))}")
                else:
                    print(f"\nâŒ Erreur : {result.get('error')}")
                
                print(f"\n{'='*60}\n")
                await asyncio.sleep(3)
            
            print("\n" + "="*60)
            print("âœ… TOUS LES TESTS TERMINÃ‰S")
            print("="*60)
            print("\nðŸ“Š Historique de la memory :")
            print(agent.memory.load_memory_variables({}))
            print("\n")
            
            await discord_client_instance.close()
        
        await discord_client_instance.client.start(discord_token)

if __name__ == "__main__":
    print("\nâš ï¸  DÃ‰PENDANCES REQUISES :")
    print("pip install langchain langchain-mistralai langchain-community discord.py\n")
    
    try:
        asyncio.run(main())
    except ImportError as e:
        print(f"âŒ DÃ©pendance manquante : {e}")
        print("\nInstalle avec :")
        print("pip install langchain langchain-mistralai langchain-community discord.py")
    except Exception as e:
        print(f"âŒ Erreur : {e}")
        import traceback
        traceback.print_exc()
